{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be883ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from wikipedia2vec import Wikipedia2Vec\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from helper_functions.cosine_similarity import cosine_similarity\n",
    "from helper_functions.obtain_articles import get_similar_articles, get_headings\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19305906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Load\n",
      "Loaded models\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Load\")\n",
    "wiki2vec = Wikipedia2Vec.load(wikipedia_model_file)\n",
    "sentence_transformer = SentenceTransformer(sentence_transformers_model)\n",
    "print(\"Loaded models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc579c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sectioned_headers(article_name):\n",
    "    print(\"Getting section headers (Using wiki2vec similarity)...\")\n",
    "    sectioned_headers = [[get_headings(article[0]), article[1]] for article in get_similar_articles(article_name, wiki2vec)]\n",
    "    return sectioned_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a8b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header_set(sectioned_headers):\n",
    "    header_scores = {}\n",
    "    for article in sectioned_headers:\n",
    "        # get all headers in the similar article\n",
    "        for header in article[0]:\n",
    "            if header in list(header_scores.keys()):\n",
    "                header_scores[header] += article[1]\n",
    "            else:\n",
    "                header_scores[header] = article[1]\n",
    "\n",
    "    header_set = [[header_score[0], header_score[1]] for header_score in header_scores.items()]  # [(\"symptoms\", 14.3234), (\"history\", 11.4321), etc.]\n",
    "    return header_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31555698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_pair_combine(header_set, header_requirement):\n",
    "    similarity_pairs = []  # [((\"symptoms\", 14.3234), (\"signs and symptoms\", 15.3221), 0.994), etc.]\n",
    "    for header_1 in range(len(header_set)):\n",
    "        for header_2 in range(header_1+1, len(header_set)):\n",
    "            similarity_pairs.append([header_set[header_1], header_set[header_2], cosine_similarity(header_set[header_1][0], header_set[header_2][0], sentence_transformer)])\n",
    "    similarity_pairs = [pair for pair in sorted(similarity_pairs, key=lambda x: x[2], reverse=True) if pair[2] > cosine_similarity_requirement]\n",
    "\n",
    "    for pair in range(len(similarity_pairs)):\n",
    "        if len(header_set) <= header_requirement:\n",
    "            break\n",
    "\n",
    "        if similarity_pairs[pair][0] in header_set and similarity_pairs[pair][1] in header_set:\n",
    "            # first header has bigger score\n",
    "            if similarity_pairs[pair][0][1] > similarity_pairs[pair][1][1]:\n",
    "                # add small score to big score and get rid of the smaller score\n",
    "                header_set[header_set.index(similarity_pairs[pair][0])][1] += \\\n",
    "                header_set[header_set.index(similarity_pairs[pair][1])][1]\n",
    "                header_set.remove(similarity_pairs[pair][1])\n",
    "            else:\n",
    "                header_set[header_set.index(similarity_pairs[pair][1])][1] += \\\n",
    "                header_set[header_set.index(similarity_pairs[pair][0])][1]\n",
    "                header_set.remove(similarity_pairs[pair][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c216210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_cutoff(header_set, header_requirement):\n",
    "        # Cut off if it is more than header_requirement\n",
    "    if len(header_set) > header_requirement:\n",
    "        generated_headings = [header[0] for header in sorted(header_set[:header_requirement], key=lambda x: x[1], reverse=True)]\n",
    "    else:\n",
    "        generated_headings = [header[0] for header in sorted(header_set, key=lambda x: x[1], reverse=True)]\n",
    "    return generated_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02580970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_and_recall(article_name, generated_headings, gt_headings):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    count = 0\n",
    "\n",
    "    keyword_matches = {}\n",
    "    ordered_keywords = []\n",
    "    for keyword in generated_headings:\n",
    "        if count == len(gt_headings):\n",
    "            break\n",
    "\n",
    "        keywords_found = []\n",
    "        for gt_heading in gt_headings:\n",
    "            if gt_heading in list(keyword_matches.values()):\n",
    "                continue\n",
    "            cosine_sim = cosine_similarity(keyword, gt_heading, sentence_transformer)\n",
    "            if cosine_sim > cosine_similarity_requirement:\n",
    "                keywords_found.append((gt_heading, cosine_sim))\n",
    "                true_positive += 1\n",
    "                break\n",
    "            if keyword in gt_heading or gt_heading in keyword:\n",
    "                keywords_found.append((gt_heading, 1))\n",
    "                true_positive += 1\n",
    "                break\n",
    "\n",
    "        if not keywords_found:\n",
    "            false_positive += 1\n",
    "\n",
    "        else:\n",
    "            best_keyword_match = (\"\", 0)\n",
    "            for keyword_found in keywords_found:\n",
    "                if keyword_found[1] > best_keyword_match[1]:\n",
    "                    best_keyword_match = keyword_found\n",
    "            keyword_matches[keyword] = best_keyword_match[0]\n",
    "            ordered_keywords.append(keyword)\n",
    "\n",
    "    false_negative = len(gt_headings) - count\n",
    "    # (Impossible to divide by 0 unless ground truth has 0 headings)\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    return (precision, recall, ordered_keywords, keyword_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaffb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_headings(ordered_keywords, keyword_matches, gt_headings):\n",
    "    ordering_metric = 0\n",
    "    pairs = []\n",
    "    for header_1 in range(len(ordered_keywords)):\n",
    "        for header_2 in range(header_1+1, len(ordered_keywords)):\n",
    "            pairs.append((ordered_keywords[header_1], ordered_keywords[header_2]))\n",
    "\n",
    "    print(\"Keyword matches: \" + str(keyword_matches))\n",
    "\n",
    "    for pair in pairs:\n",
    "        if gt_headings.index(keyword_matches[pair[0]]) < gt_headings.index(keyword_matches[pair[1]]):\n",
    "            ordering_metric += 1\n",
    "\n",
    "    if len(pairs) == 0:\n",
    "        ordering_metric = 0\n",
    "    else:\n",
    "        ordering_metric /= len(pairs)\n",
    "        \n",
    "    return ordering_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a92b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pr_values(article_name, sectioned_headers):\n",
    "    header_set = get_header_set(sectioned_headers)\n",
    "    print(header_set)\n",
    "    \n",
    "    gt_headings = get_headings(article_name)\n",
    "    \n",
    "    similarity_pair_combine(header_set, len(gt_headings))\n",
    "    print(f\"Header set: {header_set}\")\n",
    "    \n",
    "    generated_headings = header_cutoff(header_set, len(gt_headings))\n",
    "\n",
    "    average_headers = sum([len(article_headers[0]) for article_headers in sectioned_headers]) // len(sectioned_headers)\n",
    "    print(f\"Average number of headers in similar articles: {average_headers}\")\n",
    "\n",
    "    print(f\"Generated headings: {generated_headings}\")\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    ordering_metrics = []\n",
    "    for header_requirement in range(header_min_bound, len(gt_headings)+1):\n",
    "        if len(generated_headings) < header_requirement:\n",
    "            break\n",
    "        precision, recall, ordered_keywords, keyword_matches = \\\n",
    "        get_precision_and_recall(article_name, generated_headings[:header_requirement], gt_headings)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "        ordering_metric = ordered_headings(ordered_keywords, keyword_matches, gt_headings)\n",
    "        ordering_metrics.append(ordering_metric)\n",
    "\n",
    "        print(f\"Precision {precision}\")\n",
    "        print(f\"Recall {recall}\")\n",
    "        print(f\"Heading order {ordering_metric}\")\n",
    "    \n",
    "    return precisions, recalls, ordering_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f364ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Measles', 0.53669715], ['Orthomyxoviridae', 0.5243176], ['Influenzavirus_C', 0.51077414], ['1918_flu_pandemic', 0.50997454], ['Swine_influenza', 0.50933975], ['Influenza_A_virus_subtype_H5N1', 0.5092514], ['Avian_influenza', 0.50008357]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Panama_City', 0.6307721], ['List_of_cities_in_Panama', 0.62381727], ['Olá_District', 0.61495125], ['Coclé_Province', 0.61470526], ['Olá', 0.60882664], ['Chiriquí_Province', 0.60825735], ['Protected_areas_of_Panama', 0.60351366]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Exact_algorithm', 0.6048363], ['Hybrid_algorithm', 0.59737164], ['Time_complexity#Strongly_and_weakly_polynomial_time', 0.5917734], ['Sequential_algorithm', 0.58928], ['Las_Vegas_algorithm', 0.5849046], ['Output-sensitive_algorithm', 0.5847205], ['Time_complexity#Table_of_common_time_complexities', 0.58268255]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Table_tennis', 0.6389775], ['Turkey_International', 0.6089976], ['2016_Badminton_Asia_Junior_Championships', 0.6066806], ['European_Badminton_Circuit', 0.6064192], ['Welsh_International', 0.60435194], ['Polish_International', 0.59737086], ['BWF_Future_Series', 0.5947605]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Cassava', 0.54276663], ['Vigna_subterranea', 0.5383086], ['Maize', 0.5224795], ['Japanese_rice', 0.5217685], ['List_of_rice_varieties', 0.5192728], ['Wheat', 0.5132767], ['Wehani_rice', 0.51136607]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Cat', 0.5761777], ['Coydog', 0.4896183], ['FCI_Dachshund_Group', 0.48639104], ['Segugio_Italiano', 0.48629847], ['Australian_Stumpy_Tail_Cattle_Dog', 0.48518047], ['Barbet_dog', 0.4845825], ['Brazilian_Terrier', 0.4840197]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['European_dragon', 0.5325579], ['List_of_dragons_in_mythology_and_folklore', 0.49494126], ['Chinese_dragon', 0.49323097], ['Dragons_in_Greek_mythology', 0.48136798], ['Sea_serpent', 0.4731386], ['Dragonslayer', 0.46907198], ['Lindworm', 0.46864936]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Scarlett_Johansson', 0.99999994], ['Natalie_Portman', 0.47764385], ['Break_Up_(album)', 0.4482777], ['Steel_Train_(album)', 0.42483208], ['List_of_Australian_films_of_1994', 0.42279223], ['Anywhere_I_Lay_My_Head', 0.41955417], ['Manny_&_Lo', 0.41901198]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Taco_Bell', 1.0000001], ['Burger_King', 0.54968053], ['Pizza_Hut', 0.5260079], ['WingStreet', 0.51861334], ['Glen_Bell', 0.49499643], ['Wingstop', 0.49126232], [\"Dunkin'_Donuts\", 0.4894513]]\n",
      "Getting section headers (Using wiki2vec similarity)...\n",
      "Similar articles: [['Liver', 0.5869563], ['Nephron#Renal_tubule', 0.58016396], ['Nephron', 0.5518478], ['Renal_cortex', 0.548069], ['Kidney#Blood_supply', 0.5296635], ['Ureter', 0.525789], ['Glomerulus', 0.52573586]]\n",
      "[[[['signs and symptoms', 'cause', 'pathophysiology', 'diagnosis', 'prevention', 'treatment', 'prognosis', 'epidemiology', 'history', 'society and culture', 'research'], 0.53669715], [['structure', 'genome', 'replication cycle', 'classification', 'types', 'viability and disinfection', 'vaccination and prophylaxis'], 0.5243176], [['influenza c virus', 'structure and variation', 'identification', 'vaccination'], 0.51077414], [['etymologies', 'history', 'epidemiology and pathology', 'responses', 'mortality', 'effects', 'legacy', 'research', 'sex differences in mortality'], 0.50997454], [['signs and symptoms', 'virology', 'diagnosis', 'prevention', 'treatment', 'history'], 0.50933975], [['overview', 'signs and symptoms', 'genetics', 'prevention', 'treatment', 'epidemiology', 'society and culture'], 0.5092514], [['history', 'genetics', 'subtypes', 'mode of transmission', 'h5n1', 'h7n9', 'domestic animals', 'global impact', 'prevention', 'sources'], 0.50008357]], [[['history', 'geography', 'cityscape', 'economy', 'demographics', 'culture', 'sports', 'education', 'healthcare', 'transportation', 'international relations', 'gallery'], 0.6307721], [['largest cities', 'alphabetical list'], 0.62381727], [[], 0.61495125], [['pre-columbian coclé', 'administrative divisions', 'research and conservation'], 0.61470526], [[], 0.60882664], [['history', 'administrative divisions', 'climate'], 0.60825735], [[], 0.60351366]], [[[], 0.6048363], [[], 0.59737164], [['table of common time complexities', 'constant time', 'logarithmic time', 'polylogarithmic time', 'sub-linear time', 'linear time', 'quasilinear time', 'sub-quadratic time', 'polynomial time', 'superpolynomial time', 'quasi-polynomial time', 'sub-exponential time', 'exponential time', 'factorial time', 'double exponential time'], 0.5917734], [[], 0.58928], [['history', 'example', 'definition', 'applications', 'complexity class', 'optimal las vegas algorithm', 'relation to monte carlo algorithms'], 0.5849046], [['examples', 'generalizations'], 0.5847205], [['table of common time complexities', 'constant time', 'logarithmic time', 'polylogarithmic time', 'sub-linear time', 'linear time', 'quasilinear time', 'sub-quadratic time', 'polynomial time', 'superpolynomial time', 'quasi-polynomial time', 'sub-exponential time', 'exponential time', 'factorial time', 'double exponential time'], 0.58268255]], [[['history', 'equipment', 'gameplay', 'grips', 'stance', 'types of strokes', 'effects of spin', 'competitions', 'naturalization in table tennis', 'notable players', 'governance', 'variants', 'bibliography'], 0.6389775], [[], 0.6089976], [['venue', 'seed', 'medalists', 'medal table'], 0.6066806], [['prize money', 'rankings'], 0.6064192], [['past winners', 'performances by nation'], 0.60435194], [[], 0.59737086], [['features'], 0.5947605]], [[['description', 'history', 'production', 'economic importance', 'uses', 'food use', 'farming', 'genome'], 0.54276663], [['agronomic aspects', 'uses', 'physiology'], 0.5383086], [['history', 'names', 'structure and physiology', 'genetics', 'evolution', 'breeding', 'origin', 'cultivation', 'production', 'pests', 'uses', 'comparison to other staple foods', 'hazards', 'art'], 0.5224795], [['cultivation', 'cultivars', 'processing', 'uses', 'trading'], 0.5217685], [['north american varieties', 'african varieties', 'australian varieties', 'bangladeshi varieties', 'bhutanese varieties', 'burmese varieties', 'cambodian varieties', 'canadian varieties', 'chinese varieties', 'dominican varieties', 'french varieties', 'greek varieties', 'indian varieties', 'indonesian rice varieties/landraces', 'iranian varieties', 'italian varieties', 'japanese varieties', 'malaysian varieties', 'nepali varieties', 'pakistani varieties', 'philippine varieties', 'portuguese varieties', 'sri lankan varieties', 'spanish varieties', 'taiwanese varieties', 'thai varieties', 'vietnamese varieties'], 0.5192728], [['origin and history', 'farming techniques', 'physiology', 'genetics and breeding', 'varieties', 'naming', 'as a food', 'commercial use', 'production and consumption', 'agronomy', 'pests and diseases'], 0.5132767], [[], 0.51136607]], [[['etymology and naming', 'taxonomy', 'evolution', 'characteristics', 'senses', 'behavior', 'lifespan and health', 'ecology', 'interaction with humans'], 0.5761777], [[], 0.4896183], [[], 0.48639104], [['history', 'characteristics', 'use'], 0.48629847], [['history', 'breed recognition', 'appearance', 'temperament', 'activities'], 0.48518047], [['description', 'overall health', 'history', 'status in great britain (uk)'], 0.4845825], [['description'], 0.4840197]], [[['etymology', 'greek and roman dragons', 'middle ages', 'dragons in specific cultures', 'heraldry', 'modern dragons'], 0.5325579], [['asian dragons', 'european dragons', 'north american dragons', 'south american dragons', 'african dragons', 'oceanian dragons', 'common dragons with unknown origin'], 0.49494126], [['symbolic value', 'dragon worship', 'depictions of the dragon', 'cultural references', 'in popular culture', 'regional variations across asia', 'gallery'], 0.49323097], [['origins', 'list of dragons'], 0.48136798], [['mythology', 'reported sightings', 'gallery'], 0.4731386], [['description', 'dragonslayer characters'], 0.46907198], [['etymology', 'in tales', 'late belief in lindorm in sweden'], 0.46864936]], [[['early life', 'acting career', 'music career', 'public image', 'personal life', 'other ventures'], 0.99999994], [['early life and education', 'career', 'activism', 'personal life and endorsements', 'filmography and awards', 'bibliography'], 0.47764385], [['production', 'promotion', 'reception', 'track listing', 'personnel', 'chart positions', 'certifications'], 0.4482777], [[], 0.42483208], [['1994'], 0.42279223], [['critical reception', 'commercial performance', 'track listing', 'personnel', 'charts', 'release history'], 0.41955417], [['synopsis', 'cast', 'reception'], 0.41901198]], [[['history', 'menu and advertising', 'outside the united states', 'clothing line'], 1.0000001], [['history', 'structure and operations', 'franchises', 'international operations', 'controversies and legal cases', 'charitable contributions and services', 'products', 'advertising'], 0.54968053], [['history', 'concept', 'products', 'advertising', 'wingstreet', 'international', 'criticism'], 0.5260079], [['history', 'concept', 'products', 'advertising', 'wingstreet', 'international', 'criticism'], 0.51861334], [['biography', 'death'], 0.49499643], [['history', 'menu', 'wingstop charities', 'locations', 'thighstop'], 0.49126232], [['history', 'marketing', 'locations', 'notable endorsers', 'criticism', 'explanatory notes'], 0.4894513]], [[['structure', 'development', 'functions', 'clinical significance', 'society and culture', 'other animals'], 0.5869563], [['structure', 'functions', 'clinical significance', 'additional images'], 0.58016396], [['structure', 'functions', 'clinical significance', 'additional images'], 0.5518478], [[], 0.548069], [['structure', 'function', 'clinical significance', 'other animals', 'society and culture', 'history', 'additional images'], 0.5296635], [['structure', 'function', 'clinical significance', 'other animals', 'history'], 0.525789], [[], 0.52573586]]]\n",
      "Article: Influenza\n",
      "[['signs and symptoms', 1.5552883], ['cause', 0.53669715], ['pathophysiology', 0.53669715], ['diagnosis', 1.046037], ['prevention', 2.0553718], ['treatment', 1.5552883], ['prognosis', 0.53669715], ['epidemiology', 1.0459485], ['history', 2.0560951], ['society and culture', 1.0459485], ['research', 1.0466716], ['structure', 0.5243176], ['genome', 0.5243176], ['replication cycle', 0.5243176], ['classification', 0.5243176], ['types', 0.5243176], ['viability and disinfection', 0.5243176], ['vaccination and prophylaxis', 0.5243176], ['influenza c virus', 0.51077414], ['structure and variation', 0.51077414], ['identification', 0.51077414], ['vaccination', 0.51077414], ['etymologies', 0.50997454], ['epidemiology and pathology', 0.50997454], ['responses', 0.50997454], ['mortality', 0.50997454], ['effects', 0.50997454], ['legacy', 0.50997454], ['sex differences in mortality', 0.50997454], ['virology', 0.50933975], ['overview', 0.5092514], ['genetics', 1.009335], ['subtypes', 0.50008357], ['mode of transmission', 0.50008357], ['h5n1', 0.50008357], ['h7n9', 0.50008357], ['domestic animals', 0.50008357], ['global impact', 0.50008357], ['sources', 0.50008357]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header set: [['pathophysiology', 0.53669715], ['epidemiology', 1.0459485], ['history', 6.691625], ['society and culture', 4.673109], ['genome', 0.5243176], ['epidemiology and pathology', 0.50997454], ['mortality', 0.50997454], ['sex differences in mortality', 2.5659814], ['virology', 0.50933975], ['genetics', 1.009335], ['global impact', 9.25209]]\n",
      "Average number of headers in similar articles: 7\n",
      "Generated headings: ['global impact', 'history', 'society and culture', 'sex differences in mortality', 'epidemiology', 'genetics', 'pathophysiology', 'genome', 'epidemiology and pathology', 'mortality', 'virology']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-4107d45cfae3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mindex\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msectioned_headers_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Article: {article_names[index]}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0mprecisions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecalls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mordering_metrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_pr_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marticle_names\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msectioned_headers_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0mprecisions_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprecisions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mrecalls_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecalls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-9-e7a1b60a5012>\u001B[0m in \u001B[0;36mget_pr_values\u001B[0;34m(article_name, sectioned_headers)\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerated_headings\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mheader_requirement\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m             \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m         \u001B[0mprecision\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecall\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mordered_keywords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeyword_matches\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m         \u001B[0mget_precision_and_recall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marticle_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgenerated_headings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mheader_requirement\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgt_headings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Bulk of time is here!\n",
    "sectioned_headers_list = [get_sectioned_headers(article_name) for article_name in article_names]\n",
    "print(sectioned_headers_list)\n",
    "\n",
    "precisions_list = []\n",
    "recalls_list = []\n",
    "ordering_metrics_list = []\n",
    "\n",
    "for index in range(len(sectioned_headers_list)):\n",
    "    print(f\"Article: {article_names[index]}\")\n",
    "    precisions, recalls, ordering_metrics = get_pr_values(article_names[index], sectioned_headers_list[index])\n",
    "    precisions_list.append(precisions)\n",
    "    recalls_list.append(recalls)\n",
    "    ordering_metrics_list.append(ordering_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precisions_list)\n",
    "print(recalls_list)\n",
    "print(ordering_metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef386436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c620b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(section_headers_list)):\n",
    "    disp = PrecisionRecallDisplay(precision=precisions_list[index], recall=recalls_list[index])\n",
    "    disp.plot()\n",
    "    plt.title(f\"PR Curve for {article_names[index]}\")\n",
    "    plt.show()\n",
    "    plt.savefig(pr_curve_graphs + f\"/{article_names[index]}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}